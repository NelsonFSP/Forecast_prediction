{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#Download dos dados de preço das ações Itau Unibanco com ticker \"ITUB4\"\n",
    "df_ITUB4 = yf.download('ITUB4.SA', start=\"2016-01-01\", end=\"2024-03-31\")\n",
    "#Gerando um novo dataset reduzido, apenas com Data(index), alta e baixa\n",
    "df_reduced = df_ITUB4[['High', 'Low']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordenando valores por data\n",
    "df_reduced = df_reduced.sort_values(by='Date')\n",
    "#Calculando a média entre alta e baixa e atribuindo a coluna median\n",
    "df_reduced['Median'] = df_reduced.mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gerando gráfico da média de preços da ação\n",
    "plt.plot(df_reduced['Median'])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos padronizar as médias de valor do ticker\n",
    "#feature_range=(0,1)\n",
    "norm = MinMaxScaler()\n",
    "normalized = df_reduced.iloc[:, 2:3]\n",
    "df_reduced['Stand']= norm.fit_transform(normalized.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirar eventuais valores nulos\n",
    "df_reduced = df_reduced.dropna()\n",
    "#Selecionando a base de treinamento em 80% das observações\n",
    "df_training = df_reduced['Stand'].iloc[0:math.ceil(len(df_reduced) * 0.8)].values\n",
    "#Selecionando a base de testes\n",
    "df_testing = df_reduced['Stand'].iloc[math.ceil(len(df_reduced) * 0.8):len(df_reduced)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando o array de uma dimensão em um array de duas dimensões\n",
    "df_training = np.reshape(df_training, (-1,1))\n",
    "df_training.shape\n",
    "df_testing = np.reshape(df_testing, (-1,1))\n",
    "df_testing.shape\n",
    "print(*df_training[:5])\n",
    "print(*df_testing[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando as sequencias para treinamento do modelo\n",
    "training_steps_backpropagation = 100\n",
    "test_steps_backpropagation = 50\n",
    "\n",
    "x_training, y_training = [], []\n",
    "for i in range(len(df_training) - training_steps_backpropagation):\n",
    "    x_training.append(df_training[i:i+training_steps_backpropagation])\n",
    "    y_training.append(df_training[i+1:i+training_steps_backpropagation+1])\n",
    "x_training, y_training = np.array(x_training), np.array(y_training)\n",
    "\n",
    "\n",
    "x_test, y_test = [], []\n",
    "for i in range(len(df_testing) - test_steps_backpropagation):\n",
    "    x_test.append(df_testing[i:i+test_steps_backpropagation])\n",
    "    y_test.append(df_testing[i+1:i+test_steps_backpropagation+1])\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([360, 50, 1]), torch.Size([360, 50, 1]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conversão dos dados para tensores Pytorch\n",
    "x_training = torch.tensor(x_training, dtype=torch.float32)\n",
    "y_training = torch.tensor(y_training, dtype=torch.float32)\n",
    "x_training.shape, y_training.shape\n",
    "\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definição de classe do modelo LSTM\n",
    "class LSTMModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size, hidden_size, num_layers ) -> None:\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#Checagem dos resources da máquina a qual irá rodar o modelo LSTM\n",
    "device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definição dos parâmetros do modelo LSTM\n",
    "input_size = 1\n",
    "num_layers = 12\n",
    "hidden_size = 24\n",
    "output_size = 1\n",
    "\n",
    "#Definição do Modelo\n",
    "model = LSTMModel(input_size, hidden_size, num_layers).to(device)\n",
    "\n",
    "#Definição da função perda para o modelo\n",
    "loss_func = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "#Definição do otimizador\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação dos DataLoaders para o treinamento e teste\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "#DataLoader de treino\n",
    "training_data = torch.utils.data.TensorDataset(x_training, y_training)\n",
    "training_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#DataLoader de teste\n",
    "test_data = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fase de treino e tunning dos parametros\n",
    "epochs = 50\n",
    "training_hist = []\n",
    "test_hist = []\n",
    "\n",
    "#Loop de treinamento do modelo\n",
    "for epoch in range(epochs):\n",
    "    perda_total_treino = 0.0\n",
    "    \n",
    "    #Treinamento do modelo\n",
    "    model.train()\n",
    "    for batch_x_training, batch_y_training in training_loader:\n",
    "        batch_x_training, batch_y_training = batch_x_training.to(device), batch_y_training.to(device)\n",
    "        \n",
    "        predictions_training = model(batch_x_training)\n",
    "        \n",
    "        loss_training = loss_func(predictions_training, batch_y_training)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_training.backward()\n",
    "        optimizer.step\n",
    "        \n",
    "        perda_total_treino += loss_training.item()\n",
    "        \n",
    "    #Calculo da média da perda na base de treino e a acurácia do modelo\n",
    "    loss_medio_treino = perda_total_treino / len(training_loader)\n",
    "    training_hist.append(loss_medio_treino)\n",
    "    \n",
    "    #Validação do modelo na base de teste\n",
    "    model.eval()    \n",
    "    with torch.no_grad():\n",
    "        perda_total_teste = 0.0\n",
    "        \n",
    "        #Avaliação do modelo\n",
    "        for batch_x_test, batch_y_test in test_loader:\n",
    "            batch_x_test, batch_y_test = batch_x_test.to(device), batch_y_test.to(device)\n",
    "            \n",
    "            predictions_test = model(batch_x_test)\n",
    "            \n",
    "            loss_test = loss_func(predictions_test, batch_y_test)\n",
    "            \n",
    "            perda_total_teste += loss_test.item()\n",
    "\n",
    "        #Calculo da média da perda na base de teste e a acurácia do modelo\n",
    "        loss_medio_teste = perda_total_teste / len(test_loader)\n",
    "        test_hist.append(loss_medio_teste)\n",
    "    \n",
    "    #Apresentando as perdas médias na base de treino e na base de teste\n",
    "    if(epoch + 1)%10 == 0:\n",
    "        print(f'Epoca[{epoch+1}/{epochs}] - Perda de treino médio: {loss_medio_treino:.4f}, Perda de teste médio: {loss_medio_teste:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
